{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Milestone2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M4fFxMBlQNn3"
      },
      "outputs": [],
      "source": [
        "!pip install -q parlai\n",
        "!pip install -q subword_nmt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import parlai.core.torch_generator_agent as tga\n",
        "from parlai.core.agents import register_agent, Agent\n",
        "from parlai.scripts.train_model import TrainModel\n",
        "from parlai.scripts.display_model import DisplayModel"
      ],
      "metadata": {
        "id": "kVbZXbIndFFp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, embeddings, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embeddings = embeddings\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tokens):\n",
        "        embedded = self.embeddings(input_tokens)\n",
        "        _output, hidden = self.lstm(embedded)\n",
        "        return hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, embeddings, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embeddings = embeddings\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "    def forward(self, input, encoder_state, incr_state=None):\n",
        "        embedded = self.embeddings(input)\n",
        "        # previous hidden state of decoder\n",
        "        if incr_state is None:\n",
        "            state = encoder_state\n",
        "        else:\n",
        "            state = incr_state\n",
        "        output, incr_state = self.lstm(embedded, state)\n",
        "        return output, incr_state"
      ],
      "metadata": {
        "id": "sB--RkGjQPsA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(tga.TorchGeneratorModel):\n",
        "    def __init__(self, dictionary, hidden_size=512):\n",
        "        super().__init__(\n",
        "            padding_idx=dictionary[dictionary.null_token],\n",
        "            start_idx=dictionary[dictionary.start_token],\n",
        "            end_idx=dictionary[dictionary.end_token],\n",
        "            unknown_idx=dictionary[dictionary.unk_token],\n",
        "        )\n",
        "        self.embeddings = nn.Embedding(len(dictionary), hidden_size)\n",
        "        self.encoder = Encoder(self.embeddings, hidden_size)\n",
        "        self.decoder = Decoder(self.embeddings, hidden_size)\n",
        "\n",
        "    def output(self, decoder_output):\n",
        "        return F.linear(decoder_output, self.embeddings.weight)\n",
        "\n",
        "    def reorder_encoder_states(self, encoder_states, indices):\n",
        "        h, c = encoder_states\n",
        "        return h[:, indices, :], c[:, indices, :]\n",
        "\n",
        "    def reorder_decoder_incremental_state(self, incr_state, indices):\n",
        "        h, c = incr_state\n",
        "        return h[:, indices, :], c[:, indices, :]\n",
        "\n",
        "@register_agent(\"seq2seq_milestone2\")\n",
        "class S2S_MileStone2(tga.TorchGeneratorAgent):\n",
        "    def build_model(self):\n",
        "        model = EncoderDecoder(self.dict, 512)\n",
        "        self._copy_embeddings(model.embeddings.weight, self.opt['embedding_type'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "EVToaMRVdyoJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainModel.main(\n",
        "    model='seq2seq_milestone2',\n",
        "    model_file='seq2seq_milestone2/model',\n",
        "    task='personachat:both_revised',\n",
        "    embedding_type='fasttext_cc',\n",
        "    batchsize=7,\n",
        "    max_train_time=3600,\n",
        "    dynamic_batching='full',\n",
        "    truncate = 256,\n",
        "    metrics = 'ppl,bleu,rouge',\n",
        ")"
      ],
      "metadata": {
        "id": "Jo84hkdXQuKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DisplayModel.main(\n",
        "    task='personachat:both_revised',\n",
        "    model_file='seq2seq_milestone2/model',\n",
        "    num_examples=35,\n",
        ")"
      ],
      "metadata": {
        "id": "dMqDtRkqQ6rt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}